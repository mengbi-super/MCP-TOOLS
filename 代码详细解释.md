# log_analyzer_tool.py 代码详细解释

本文档逐行解释 `log_analyzer_tool.py` 文件的处理逻辑。

---

## 一、文件头部和导入部分（第 1-34 行）

### 第 1 行：Shebang
```python
#!/usr/bin/env python3
```
- **作用**：指定脚本使用 Python 3 解释器执行
- **说明**：在 Unix/Linux 系统中，如果文件有执行权限，可以直接运行

### 第 2-7 行：模块文档字符串
```python
"""
日志检索和分析工具

使用 fastmcp 创建，能够分析 logback-spring.xml 配置的日志文件，
检测代码缺陷并自动修复。
"""
```
- **作用**：描述模块的功能和用途
- **说明**：这是 Python 的文档字符串，可以通过 `__doc__` 访问

### 第 9-14 行：导入标准库
```python
import os          # 操作系统接口，用于路径操作、环境变量等
import re          # 正则表达式，用于模式匹配
import xml.etree.ElementTree as ET  # XML 解析，用于解析 logback 配置
from pathlib import Path  # 路径操作（虽然导入了但未使用）
from typing import Any, Dict, List, Optional  # 类型提示
from datetime import datetime  # 日期时间，用于记录分析时间
```

### 第 16-20 行：读取默认 logback 配置路径
```python
DEFAULT_LOGBACK_CONFIG = os.getenv(
    "LOGBACK_CONFIG_PATH",
    "src/resource/logback-spring.xml"
)
```
- **逻辑**：
  1. 尝试从环境变量 `LOGBACK_CONFIG_PATH` 读取
  2. 如果环境变量不存在，使用默认值 `"src/resource/logback-spring.xml"`
- **用途**：提供配置的默认值，支持通过环境变量覆盖

### 第 22-26 行：读取日志文件路径和应用包名环境变量
```python
DEFAULT_ERROR_LOG_PATH = os.getenv("ERROR_LOG_PATH", None)
DEFAULT_WARN_LOG_PATH = os.getenv("WARN_LOG_PATH", None)
DEFAULT_ALL_LOG_PATH = os.getenv("ALL_LOG_PATH", None)

# 从环境变量读取应用包名（用于过滤堆栈跟踪）
DEFAULT_APP_PACKAGE = os.getenv("APP_PACKAGE", None)
```
- **逻辑**：
  - 从环境变量读取三种日志级别的文件路径
  - 从环境变量读取应用包名（用于过滤堆栈跟踪，只保留应用包下的堆栈信息）
- **说明**：
  - 如果日志路径环境变量不存在，返回 `None`，后续会从 logback 配置中读取
  - 如果应用包名环境变量不存在，返回 `None`，后续会从应用名称自动推断

### 第 27-33 行：尝试导入 FastMCP
```python
try:
    from fastmcp import FastMCP
    FASTMCP_AVAILABLE = True
except ImportError:
    FastMCP = None
    FASTMCP_AVAILABLE = False
```
- **逻辑**：
  1. 尝试导入 `fastmcp` 库
  2. 如果成功，设置 `FASTMCP_AVAILABLE = True`
  3. 如果失败（ImportError），设置 `FastMCP = None` 和 `FASTMCP_AVAILABLE = False`
- **目的**：优雅降级，即使没有安装 fastmcp 也能运行基础功能

---

## 二、LogAnalyzer 类 - 初始化方法（第 36-85 行）

### 第 36-37 行：类定义
```python
class LogAnalyzer:
    """日志分析器"""
```

### 第 39-45 行：`__init__` 方法签名
```python
def __init__(
    self,
    logback_config_path: Optional[str] = None,
    error_log_path: Optional[str] = None,
    warn_log_path: Optional[str] = None,
    all_log_path: Optional[str] = None
):
```
- **参数说明**：
  - `logback_config_path`：logback 配置文件路径（可选）
  - `error_log_path`：错误日志文件路径（可选）
  - `warn_log_path`：警告日志文件路径（可选）
  - `all_log_path`：全部日志文件路径（可选）

### 第 63-65 行：确定 logback 配置文件路径
```python
if logback_config_path is None:
    logback_config_path = DEFAULT_LOGBACK_CONFIG
self.logback_config_path = logback_config_path
```
- **逻辑**：如果参数为 `None`，使用默认配置路径
- **优先级**：方法参数 > 环境变量 > 默认值

### 第 66 行：解析 logback 配置
```python
self.config = self._parse_logback_config()
```
- **作用**：调用私有方法解析 XML 配置文件，返回配置字典

### 第 68-77 行：处理日志路径
```python
# 获取配置中的日志路径
config_log_path = self.config.get("log_path")

# 如果配置中有路径，在 Windows 上需要转换 Linux 路径格式
if config_log_path:
    self.log_path = self._convert_path_for_platform(config_log_path)
else:
    # 默认日志路径：Windows 使用磁盘根目录下的 /data/logs，Linux 使用 /data/logs
    default_log_path = self._get_default_log_path_for_platform()
    self.log_path = default_log_path
```
- **逻辑**：
  1. 从配置中获取 `log_path`
  2. 如果存在，转换为当前平台格式（Windows/Linux）
  3. 如果不存在，使用平台默认路径
- **关键**：Windows 上会将 `/data/logs` 转换为 `D:\data\logs`（根据项目所在磁盘）

### 第 79-117 行：获取应用名称和应用包名（动态推断，不硬编码）
```python
# 获取应用名称，优先从配置中读取，如果配置中没有则尝试从环境变量或项目路径推断
app_name = self.config.get("app_name")
if not app_name:
    # 尝试从环境变量获取
    app_name = os.getenv("SPRING_APPLICATION_NAME") or os.getenv("APP_NAME")
    if not app_name:
        # 尝试从当前工作目录推断（取目录名）
        try:
            current_dir = os.getcwd()
            # 获取最后一级目录名作为应用名称
            app_name = os.path.basename(os.path.normpath(current_dir))
            # 如果目录名是常见的项目根目录名，尝试获取上一级
            if app_name in ["src", "target", "build", "dist", "bin"]:
                parent_dir = os.path.dirname(os.path.normpath(current_dir))
                app_name = os.path.basename(parent_dir) if parent_dir else "unknown-app"
        except Exception:
            app_name = "unknown-app"

self.app_name = app_name or "unknown-app"

# 获取应用包名（用于过滤堆栈跟踪，只保留应用包下的堆栈信息）
# 优先级：环境变量 > 从应用名称推断 > None
app_package = DEFAULT_APP_PACKAGE
if not app_package:
    # 尝试从应用名称推断包名（常见模式：应用名 -> 包名）
    # 例如：cdc-major-disease-service -> cdc.major.disease
    if app_name and app_name != "unknown-app":
        # 将应用名称转换为可能的包名格式
        # 移除常见后缀（-service, -api 等）
        name_without_suffix = re.sub(r'[-_](service|api|app|web|core)$', '', app_name, flags=re.IGNORECASE)
        # 将连字符或下划线替换为点，转换为包名格式
        potential_package = name_without_suffix.replace('-', '.').replace('_', '.')
        # 如果看起来像包名（包含点），则使用
        if '.' in potential_package:
            app_package = potential_package
self.app_package = app_package
```
- **应用名称优先级**：
  1. logback 配置中的 `app_name`（从 `contextName` 或 `spring.application.name` 属性）
  2. 环境变量 `SPRING_APPLICATION_NAME` 或 `APP_NAME`
  3. 从当前工作目录推断（取目录名）
  4. 如果都失败，使用 `"unknown-app"` 作为默认值
- **应用包名优先级**：
  1. 环境变量 `APP_PACKAGE`（最高优先级）
  2. 从应用名称自动推断（如 `cdc-major-disease-service` → `cdc.major.disease`）
  3. 如果都失败，使用框架包过滤机制（过滤掉常见的框架包）
- **说明**：
  - 不再硬编码应用名称，支持不同系统使用不同的应用名称
  - 应用包名用于过滤堆栈跟踪，只保留应用包下的堆栈信息，移除底层框架信息

### 第 81-84 行：存储外部配置的日志文件路径
```python
# 存储外部配置的日志文件路径（优先级：参数 > 环境变量 > None）
self.error_log_path = error_log_path or DEFAULT_ERROR_LOG_PATH
self.warn_log_path = warn_log_path or DEFAULT_WARN_LOG_PATH
self.all_log_path = all_log_path or DEFAULT_ALL_LOG_PATH
```
- **优先级**：方法参数 > 环境变量 > None
- **说明**：使用 `or` 运算符，如果参数为 `None`，使用环境变量值

---

## 三、路径处理方法（第 86-138 行）

### 第 86-102 行：`_get_default_log_path_for_platform` 方法
```python
def _get_default_log_path_for_platform(self) -> str:
    if os.name == 'nt':  # Windows
        current_dir = os.getcwd()  # 获取当前工作目录
        drive = os.path.splitdrive(current_dir)[0]  # 提取磁盘盘符，如 "D:"
        return os.path.join(drive + os.sep, "data", "logs")  # 返回 "D:\data\logs"
    else:  # Linux/Mac
        return "/data/logs"
```
- **逻辑**：
  1. 判断操作系统类型（`os.name == 'nt'` 表示 Windows）
  2. Windows：获取当前目录的磁盘盘符，拼接 `\data\logs`
  3. Linux/Mac：直接返回 `/data/logs`
- **示例**：项目在 `D:\workspaceNew\...` → 返回 `D:\data\logs`

### 第 104-132 行：`_convert_path_for_platform` 方法
```python
def _convert_path_for_platform(self, path: str) -> str:
    if not path:
        return path
    
    # 如果是 Windows 平台，且路径是 Linux 格式（以 / 开头但不是 //）
    if os.name == 'nt' and path.startswith('/') and not path.startswith('//'):
        current_dir = os.getcwd()
        drive = os.path.splitdrive(current_dir)[0]  # 例如：D:
        
        # 将 Linux 路径转换为 Windows 路径
        # /data/logs -> D:\data\logs
        path_parts = path.lstrip('/').split('/')  # 移除开头的 /，分割路径
        windows_path = os.path.join(drive + os.sep, *path_parts)  # 使用 os.path.join 拼接
        return windows_path
    
    return path
```
- **逻辑**：
  1. 如果路径为空，直接返回
  2. 如果是 Windows 且路径是 Linux 格式（以 `/` 开头但不是 `//` UNC 路径）
  3. 提取磁盘盘符
  4. 移除开头的 `/`，分割路径组件
  5. 使用 `os.path.join` 拼接为 Windows 路径
- **示例**：`/data/logs/test.log` → `D:\data\logs\test.log`

### 第 134-137 行：重复代码（应该删除）
```python
# 存储外部配置的日志文件路径（优先级：参数 > 环境变量 > None）
self.error_log_path = error_log_path or DEFAULT_ERROR_LOG_PATH
self.warn_log_path = warn_log_path or DEFAULT_WARN_LOG_PATH
self.all_log_path = all_log_path or DEFAULT_ALL_LOG_PATH
```
- **说明**：这段代码是重复的，已经在第 82-84 行执行过，应该删除

---

## 四、日志文件路径获取方法（第 139-173 行）

### 第 139-154 行：`_get_default_log_path` 方法
```python
def _get_default_log_path(self, log_level: str) -> str:
    if log_level == "error":
        return f"{self.log_path}/{self.app_name}/log_error.log"
    elif log_level == "warn":
        return f"{self.log_path}/{self.app_name}/log_warn.log"
    else:
        return f"{self.log_path}/{self.app_name}/all.log"
```
- **逻辑**：根据日志级别返回默认日志文件路径
- **格式**：`{log_path}/{app_name}/{log_file_name}`
- **说明**：使用正斜杠 `/`，后续会通过 `_convert_path_for_platform` 转换

### 第 156-173 行：`_get_log_file_path` 方法
```python
def _get_log_file_path(self, log_level: str) -> str:
    if log_level == "error" and self.error_log_path:
        return self.error_log_path
    elif log_level == "warn" and self.warn_log_path:
        return self.warn_log_path
    elif log_level == "all" and self.all_log_path:
        return self.all_log_path
    else:
        return self._get_default_log_path(log_level)
```
- **优先级**：外部配置的路径 > 默认路径（从 logback 配置读取）
- **逻辑**：如果外部配置存在，使用外部配置；否则使用默认路径

---

## 五、配置解析方法（第 175-218 行）

### 第 175-218 行：`_parse_logback_config` 方法
```python
def _parse_logback_config(self) -> Dict[str, Any]:
    config = {}
    try:
        if not os.path.exists(self.logback_config_path):
            return config  # 文件不存在，返回空配置
        
        tree = ET.parse(self.logback_config_path)  # 解析 XML 文件
        root = tree.getroot()  # 获取根元素
        
        # 提取 contextName
        context_name = root.find("contextName")
        if context_name is not None:
            config["app_name"] = context_name.text
        
        # 提取属性
        for prop in root.findall(".//property"):  # 查找所有 property 元素
            name = prop.get("name", "")
            value = prop.get("value", "")
            
            if name == "logging.path":
                config["log_path"] = value
            elif name == "spring.application.name":
                config["app_name"] = value
        
        # 提取日志文件路径
        appenders = []
        for appender in root.findall(".//appender"):  # 查找所有 appender 元素
            appender_name = appender.get("name", "")
            file_elem = appender.find("file")
            if file_elem is not None:
                file_path = file_elem.text
                if file_path:
                    appenders.append({
                        "name": appender_name,
                        "file": file_path
                    })
        
        config["appenders"] = appenders
        
    except Exception as e:
        print(f"解析 logback 配置时出错: {e}")
    
    return config
```
- **逻辑**：
  1. 检查文件是否存在
  2. 使用 `ElementTree` 解析 XML
  3. 提取 `contextName` 作为应用名称
  4. 遍历所有 `property` 元素，提取 `logging.path` 和 `spring.application.name`
  5. 遍历所有 `appender` 元素，提取日志文件路径
  6. 返回配置字典

---

## 六、日志文件读取方法（第 220-259 行）

### 第 220-259 行：`_read_log_file` 方法
```python
def _read_log_file(self, file_path: str, max_lines: int = 1000) -> List[str]:
    lines = []
    try:
        # 展开变量
        expanded_path = file_path.replace("${logging.path}", self.log_path)
        expanded_path = expanded_path.replace("${spring.application.name}", self.app_name)
        
        # 转换路径格式（如果是 Linux 路径在 Windows 上）
        expanded_path = self._convert_path_for_platform(expanded_path)
        
        # 检查文件是否存在
        if not os.path.exists(expanded_path):
            # 尝试原始路径（如果不同）
            if expanded_path != file_path:
                original_path = self._convert_path_for_platform(file_path)
                if os.path.exists(original_path):
                    expanded_path = original_path
                else:
                    return lines  # 文件不存在，返回空列表
            else:
                return lines
        
        # 读取文件
        with open(expanded_path, 'r', encoding='utf-8', errors='ignore') as f:
            lines = f.readlines()[-max_lines:]  # 只读取最后 N 行
    except Exception as e:
        # 只在调试模式下打印错误
        if os.getenv("LOG_ANALYZER_DEBUG"):
            print(f"读取日志文件 {file_path} 时出错: {e}")
    
    return lines
```
- **逻辑**：
  1. 展开变量：将 `${logging.path}` 和 `${spring.application.name}` 替换为实际值
  2. 转换路径格式（Windows/Linux）
  3. 检查文件是否存在，如果不存在尝试原始路径
  4. 使用 `utf-8` 编码读取，`errors='ignore'` 忽略编码错误
  5. 只读取最后 `max_lines` 行（使用切片 `[-max_lines:]`）
  6. 异常处理：只在调试模式下打印错误

---

## 七、路径验证方法（第 261-315 行）

### 第 261-315 行：`_validate_log_path` 方法
```python
def _validate_log_path(self, log_path: str) -> Dict[str, Any]:
    result = {
        "exists": False,
        "path": log_path,
        "suggestions": []
    }
    
    if not log_path:
        return result
    
    # 检查文件是否存在
    file_exists = os.path.exists(log_path)
    
    # 在 Windows 上，检查是否是 Linux 路径格式
    is_linux_path_on_windows = False
    if os.name == 'nt':  # Windows
        if log_path.startswith('/') and not log_path.startswith('//'):
            # 检查是否是典型的 Linux 路径
            linux_path_patterns = ['/data/', '/var/', '/tmp/', '/usr/', '/opt/']
            if any(log_path.startswith(pattern) for pattern in linux_path_patterns):
                is_linux_path_on_windows = True
    
    # 如果文件存在，且不是 Linux 路径在 Windows 上，返回成功
    if file_exists and not is_linux_path_on_windows:
        result["exists"] = True
        return result
    
    # 文件不存在或检测到 Linux 路径在 Windows 上
    if is_linux_path_on_windows:
        result["suggestions"].append(
            "检测到 Linux 路径格式（/data/logs），在 Windows 上可能不存在。"
        )
        result["suggestions"].append(
            "建议：使用环境变量 ERROR_LOG_PATH 指定 Windows 路径，"
            "例如：D:\\logs\\error.log 或使用相对路径 logs\\error.log"
        )
    elif not file_exists:
        result["suggestions"].append(f"日志文件不存在：{log_path}")
        result["suggestions"].append(
            "建议：检查路径是否正确，或使用环境变量配置日志文件路径"
        )
    
    return result
```
- **逻辑**：
  1. 初始化结果字典
  2. 检查文件是否存在
  3. 在 Windows 上检测 Linux 路径格式
  4. 如果文件存在且路径格式正确，返回成功
  5. 否则，添加建议信息
- **用途**：提供友好的错误提示和解决建议

---

## 八、日志内容处理方法（第 408-520 行）

### 第 408-475 行：`_extract_key_info` 方法
```python
def _extract_key_info(self, log_line: str, max_length: int = 200) -> str:
    if not log_line:
        return ""
    
    # 移除常见的冗余前缀（时间戳、PID、线程ID等）
    cleaned = re.sub(r'^\d{4}-\d{2}-\d{2}\s+\d{2}:\d{2}:\d{2}\.\d{3}\s+\w+\s+\d+\s+[^\s]+\s+[^\s]+\s+---\s+\[[^\]]+\]\s+[^\s]+\s*:\s*', '', log_line)
    
    # 如果清理后为空，使用原始行
    if not cleaned.strip():
        cleaned = log_line
    
    # 提取异常信息（Exception后面的内容通常是关键）
    exception_match = re.search(r'(Exception|Error|Failed|Timeout|denied)[^:]*:?\s*(.+?)(?:\s+at\s+|\s*$)', cleaned, re.IGNORECASE)
    if exception_match:
        cleaned = exception_match.group(0).strip()
    
    # 处理堆栈跟踪：保留应用包下的堆栈信息，过滤底层框架信息
    if 'at ' in cleaned:
        # 分割异常信息和堆栈跟踪
        parts = cleaned.split('at ')
        exception_part = parts[0].strip()
        stack_trace = 'at ' + 'at '.join(parts[1:]) if len(parts) > 1 else ""
        
        if stack_trace:
            # 过滤堆栈跟踪，只保留应用包下的信息
            filtered_stack = self._filter_stack_trace(stack_trace)
            if filtered_stack:
                cleaned = exception_part + " " + filtered_stack
            else:
                # 如果没有应用包的堆栈信息，只保留异常信息
                cleaned = exception_part
    
    # 限制长度
    if len(cleaned) > max_length:
        cleaned = cleaned[:max_length] + "..."
    
    return cleaned.strip()
```
- **逻辑**：
  1. 使用正则表达式移除日志前缀（时间戳、PID、线程ID等）
  2. 提取异常信息（Exception、Error 等关键词后的内容）
  3. **智能处理堆栈跟踪**：
     - 分割异常信息和堆栈跟踪
     - 调用 `_filter_stack_trace` 过滤堆栈，只保留应用包下的信息
     - 如果找到应用包的堆栈信息，保留；否则只保留异常信息
  4. 限制长度，超过 `max_length` 截断并添加 `...`
- **目的**：减少 token 消耗，同时保留有用的应用包堆栈信息，帮助定位问题

### 第 477-520 行：`_filter_stack_trace` 方法
```python
def _filter_stack_trace(self, stack_trace: str) -> str:
    """
    过滤堆栈跟踪，只保留应用包下的堆栈信息，移除底层框架信息
    """
    if not stack_trace:
        return ""
    
    # 常见的框架包前缀（需要过滤掉）
    framework_packages = [
        'java.', 'javax.', 'sun.', 'com.sun.',
        'org.springframework.', 'org.apache.', 'org.hibernate.',
        'ch.qos.logback.', 'org.slf4j.', 'com.zaxxer.',
        'com.alibaba.', 'io.netty.', 'reactor.',
        'org.mybatis.', 'com.baomidou.', 'com.mysql.',
        'oracle.', 'com.microsoft.', 'com.ibm.'
    ]
    
    lines = stack_trace.split('\n')
    filtered_lines = []
    
    for line in lines:
        line = line.strip()
        if not line or not line.startswith('at '):
            continue
        
        # 检查是否是应用包的堆栈信息
        is_app_package = False
        
        if self.app_package:
            # 如果配置了应用包名，检查是否属于应用包
            # 堆栈格式：at com.example.Service.method(Service.java:123)
            if self.app_package in line:
                is_app_package = True
        else:
            # 如果没有配置包名，过滤掉明显的框架包
            is_framework = any(line.startswith(f'at {pkg}') for pkg in framework_packages)
            if not is_framework:
                # 不是框架包，可能是应用代码
                is_app_package = True
        
        if is_app_package:
            filtered_lines.append(line)
    
    # 如果找到了应用包的堆栈信息，返回（最多保留3层）
    if filtered_lines:
        return '\n'.join(filtered_lines[:3])
    
    return ""
```
- **逻辑**：
  1. 定义常见的框架包前缀列表（java., javax., org.springframework. 等）
  2. 分割堆栈跟踪为多行
  3. 对每一行进行判断：
     - 如果配置了 `app_package`，检查堆栈行是否包含应用包名
     - 如果没有配置包名，检查是否属于框架包，如果不是框架包则保留
  4. 收集应用包的堆栈信息（最多保留 3 层）
  5. 返回过滤后的堆栈跟踪
- **目的**：
  - 保留应用包下的堆栈信息，帮助定位问题代码位置（类名、方法名、行号）
  - 过滤掉底层框架信息，减少 token 消耗
  - 在保留有用信息和减少 token 消耗之间取得平衡

### 第 354-380 行：`_is_relevant_log_line` 方法
```python
def _is_relevant_log_line(self, line: str) -> bool:
    if not line or len(line.strip()) < 10:
        return False
    
    # 过滤掉明显的无关信息
    irrelevant_patterns = [
        r'^\s*$',  # 空行
        r'DEBUG\s+.*',  # DEBUG 级别日志
        r'INFO\s+.*启动',  # 启动信息
        r'INFO\s+.*关闭',  # 关闭信息
        r'INFO\s+.*连接',  # 普通连接信息
    ]
    
    for pattern in irrelevant_patterns:
        if re.match(pattern, line, re.IGNORECASE):
            return False
    
    return True
```
- **逻辑**：
  1. 检查行是否为空或过短（少于 10 个字符）
  2. 使用正则表达式匹配无关模式
  3. 如果匹配到任何无关模式，返回 `False`（不相关）
  4. 否则返回 `True`（相关）
- **目的**：过滤无关日志，只分析重要内容

---

## 九、日志分析方法（第 524-609 行）

### 第 524-531 行：`analyze_logs` 方法签名
```python
def analyze_logs(
    self,
    log_level: str = "error",
    max_lines: int = 1000,
    error_log_path: Optional[str] = None,
    warn_log_path: Optional[str] = None,
    all_log_path: Optional[str] = None
) -> Dict[str, Any]:
```
- **参数说明**：
  - `log_level`：日志级别（error, warn, all）
  - `max_lines`：最大读取行数
  - `error_log_path`、`warn_log_path`、`all_log_path`：可选的日志文件路径

### 第 545-567 行：确定日志文件路径并读取
```python
# 确定日志文件路径（优先级：方法参数 > 实例配置 > logback 配置）
log_file = None
if log_level == "error":
    log_file = error_log_path or self.error_log_path
elif log_level == "warn":
    log_file = warn_log_path or self.warn_log_path
else:  # all
    log_file = all_log_path or self.all_log_path

# 如果外部配置都没有，从 logback 配置中读取
if log_file is None:
    log_file = self._get_log_file_path(log_level)

log_files = [log_file]

all_log_lines = []
for log_file in log_files:
    lines = self._read_log_file(log_file, max_lines)
    all_log_lines.extend(lines)
```
- **优先级**：方法参数 > 实例配置 > logback 配置
- **逻辑**：读取日志文件，将所有行合并到 `all_log_lines` 列表

### 第 569-585 行：智能分析日志行，检测异常
```python
# 分析日志行 - 智能分析模式：自动提取所有异常信息，交给大模型分析
for line_num, line in enumerate(all_log_lines, 1):
    # 过滤无关日志行
    if not self._is_relevant_log_line(line):
        continue
    
    # 检测是否包含异常信息（自动识别所有异常类型，不限于预定义模式）
    exception_info = self._extract_exception_info(line)
    if exception_info:
        defects.append({
            "line_number": line_num,
            "log_line": exception_info["key_info"],
            "defect_type": exception_info["exception_type"],
            "severity": exception_info["severity"],
            "pattern": exception_info.get("pattern", ""),
            "exception_message": exception_info.get("exception_message", ""),
            "suggestion": None  # 让大模型分析生成建议
        })
```
- **逻辑**：
  1. 遍历所有日志行
  2. 过滤无关日志行
  3. 使用 `_extract_exception_info` 方法智能提取异常信息
  4. 如果检测到异常：
     - 提取关键信息（减少 token）
     - 自动识别异常类型
     - 自动推断严重程度
     - 创建缺陷字典，`suggestion` 设为 `None`，交给大模型分析生成建议
- **优势**：不限于预定义模式，可以识别所有类型的异常

### 第 587-609 行：排序、限制数量并返回结果
```python
# 按严重程度排序，优先返回严重的问题
defects.sort(key=lambda x: {"critical": 0, "high": 1, "medium": 2}.get(x["severity"], 3))

# 限制返回数量，避免消耗太多token（最多返回50个）
max_defects = 50
defects_limited = defects[:max_defects]

# 验证日志文件路径
path_validation = self._validate_log_path(log_files[0] if log_files else "")
warnings = []
if path_validation["suggestions"]:
    warnings.extend(path_validation["suggestions"][:2])  # 只添加前2个建议

return {
    "total_defects": len(defects),
    "defects": defects_limited,
    "log_files_analyzed": log_files,
    "analysis_time": datetime.now().isoformat(),
    "note": f"显示前 {min(max_defects, len(defects))} 个缺陷（按严重程度排序）。智能分析模式：自动提取所有异常信息，请AI分析每个异常并生成修复建议。" if len(defects) > max_defects else "智能分析模式：自动提取所有异常信息，请AI分析每个异常并生成修复建议。",
    "warnings": warnings if warnings else None
}
```
- **逻辑**：
  1. 按严重程度排序（critical < high < medium）
  2. 限制返回数量（最多 50 个）
  3. 验证路径，收集警告信息
  4. 返回结果字典，包含智能分析模式说明

---

## 十、异常信息提取方法（第 330-406 行）

### 第 330-383 行：`_extract_exception_info` 方法
```python
def _extract_exception_info(self, log_line: str) -> Optional[Dict[str, Any]]:
    """
    智能提取异常信息（不限于预定义模式）
    """
    # 提取关键信息
    key_info = self._extract_key_info(log_line, max_length=200)
    
    # 检测异常类型（使用更通用的模式）
    # 匹配 Java 异常：ExceptionName: message
    exception_match = re.search(r'(\w+Exception|\w+Error)(?:\s*:\s*|\s+)(.+?)(?:\s+at\s+|\s*$)', log_line, re.IGNORECASE)
    if exception_match:
        exception_type = exception_match.group(1)
        exception_message = exception_match.group(2).strip()[:100]
        severity = self._infer_severity(exception_type)
        return {
            "key_info": key_info,
            "exception_type": exception_type,
            "exception_message": exception_message,
            "severity": severity,
            "pattern": exception_type
        }
    
    # 检测其他错误模式（如 "Error:", "Failed:", "denied" 等）
    # ...
```
- **逻辑**：
  1. 提取关键信息（去除冗余前缀）
  2. 使用通用正则表达式匹配所有异常类型（`Exception` 和 `Error`）
  3. 提取异常类型和异常消息
  4. 自动推断严重程度
  5. 如果未匹配到异常，尝试匹配其他错误模式
- **优势**：不限于预定义模式，可以识别所有异常类型

### 第 385-406 行：`_infer_severity` 方法
```python
def _infer_severity(self, exception_type: str) -> str:
    """
    根据异常类型推断严重程度
    """
    exception_type_lower = exception_type.lower()
    
    # Critical 级别
    if any(keyword in exception_type_lower for keyword in ['outofmemory', 'stackoverflow']):
        return "critical"
    
    # High 级别
    if any(keyword in exception_type_lower for keyword in ['nullpointer', 'indexoutofbounds', 'classnotfound']):
        return "high"
    
    # Medium 级别（默认）
    return "medium"
```
- **逻辑**：根据异常类型名称中的关键词推断严重程度
- **说明**：智能分析模式会自动推断严重程度，无需预定义

---

## 十一、自动修复方法（第 504-540 行）

### 第 504-540 行：`auto_fix_code` 方法
```python
def auto_fix_code(self, defect_info: Dict[str, Any], source_code_path: Optional[str] = None) -> Dict[str, Any]:
    fixes = []
    defect_type = defect_info.get("defect_type", "")
    pattern = defect_info.get("pattern", "")
    
    fix_templates = {
        "空指针异常": {
            "before": "obj.method()",
            "after": "if obj is not None:\n    obj.method()",
            "description": "添加空值检查"
        },
        # ... 其他模板
    }
    
    for key, template in fix_templates.items():
        if key in defect_type:
            fixes.append(template)
            break
    
    return {
        "defect": defect_info,
        "fixes": fixes,
        "status": "suggested" if fixes else "manual_review_required"
    }
```
- **逻辑**：根据缺陷类型匹配修复模板，返回修复建议
- **说明**：这里只提供模板，不实际修改代码

---

## 十二、FastMCP 工具定义（第 543-702 行）

### 第 544-545 行：创建 FastMCP 服务器
```python
if FASTMCP_AVAILABLE:
    mcp = FastMCP("日志检索和分析工具")
```
- **说明**：只有在 fastmcp 可用时才创建服务器

### 第 547-580 行：`analyze_logs` 工具
```python
@mcp.tool()
def analyze_logs(...):
    analyzer = LogAnalyzer(...)
    return analyzer.analyze_logs(log_level, max_lines)
```
- **作用**：将 `LogAnalyzer.analyze_logs` 方法暴露为 MCP 工具
- **说明**：每次调用都创建新的 `LogAnalyzer` 实例

### 第 582-595 行：`get_logback_config` 工具
```python
@mcp.tool()
def get_logback_config(logback_config: Optional[str] = None) -> Dict[str, Any]:
    analyzer = LogAnalyzer(logback_config)
    return analyzer.config
```
- **作用**：获取 logback 配置信息

### 第 597-613 行：`auto_fix_defect` 工具
```python
@mcp.tool()
def auto_fix_defect(defect_info: Dict[str, Any], source_code_path: Optional[str] = None) -> Dict[str, Any]:
    analyzer = LogAnalyzer()
    return analyzer.auto_fix_code(defect_info, source_code_path)
```
- **作用**：根据缺陷信息生成修复建议

### 第 615-702 行：`search_logs` 工具
```python
@mcp.tool()
def search_logs(keyword: str, log_level: str = "all", ...) -> Dict[str, Any]:
    analyzer = LogAnalyzer(...)
    # 获取日志文件路径
    # 读取日志文件
    # 搜索关键词
    # 返回匹配结果
```
- **逻辑**：
  1. 创建 `LogAnalyzer` 实例
  2. 确定日志文件路径
  3. 读取日志文件
  4. 过滤无关日志行
  5. 搜索关键词（不区分大小写）
  6. 提取关键信息
  7. 限制返回数量（最多 30 个）
  8. 返回结果

---

## 十三、主函数和入口（第 705-740 行）

### 第 705-725 行：`main` 函数
```python
def main():
    """主函数 - 用于测试"""
    if FastMCP is None:
        print("错误: 未安装 fastmcp 库")
        return
    
    analyzer = LogAnalyzer()
    print("Logback 配置:")
    print(analyzer.config)
    
    result = analyzer.analyze_logs("error", 100)
    print(f"发现 {result['total_defects']} 个缺陷")
    for defect in result['defects'][:5]:
        # 打印缺陷信息
```
- **作用**：测试模式，用于直接运行脚本时测试功能

### 第 728-739 行：程序入口
```python
if __name__ == "__main__":
    if FASTMCP_AVAILABLE:
        try:
            mcp.run()  # 运行 FastMCP 服务器
        except Exception as e:
            print(f"运行 FastMCP 服务器时出错: {e}")
            print("切换到测试模式...")
            main()
    else:
        main()  # 运行测试
```
- **逻辑**：
  1. 如果 fastmcp 可用，尝试运行 MCP 服务器
  2. 如果运行失败，切换到测试模式
  3. 如果 fastmcp 不可用，直接运行测试

---

## 总结

### 核心流程

1. **初始化**：读取配置（环境变量、logback XML）
2. **路径处理**：转换跨平台路径（Windows/Linux）
3. **读取日志**：从文件读取日志行（只读最后 N 行）
4. **过滤处理**：过滤无关日志，提取关键信息
5. **智能分析**：自动提取所有异常信息（不限于预定义模式）
6. **异常识别**：自动识别异常类型和严重程度
7. **返回结果**：排序、限制数量、返回结果，交给大模型分析生成修复建议

### 关键设计

- **智能分析模式**：自动提取所有异常信息，不限于预定义模式，交给大模型分析
- **优先级机制**：方法参数 > 实例配置 > 环境变量 > logback 配置 > 默认值
- **跨平台支持**：自动转换 Linux 路径为 Windows 路径
- **Token 优化**：提取关键信息，过滤无关内容，限制返回数量
- **优雅降级**：fastmcp 不可用时仍可运行基础功能
- **错误处理**：异常捕获，提供友好提示
